{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f72bcc5-8402-4c66-bdcf-29617fec60b0",
   "metadata": {},
   "source": [
    "# Lecture 13: Algoritmo de Vecino Más Cercano (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712cdb34-9d41-43b8-bfdc-ceaad5944338",
   "metadata": {},
   "source": [
    "La clasificación es importante para los humanos. Siempre estamos clasificando: si alguien es amigo o enemigo, si alguien está enfermo o no, si la comida está podrida o no, entre otros. Incluso, este proceso es de vida o muerte: clasificamos si algo es peligroso o no. Por ello, los algoritmos de Machine Learning se han centrado en la clasificación de cosas: si algo es un perro o un gato, si la cara que se reconoce es la tuya para darte acceso a tu teléfono o no, si alguien tiene cáncer o no.\n",
    "\n",
    "Hoy vamos a aprender sobre el algoritmo de vecino más cercano kNN (k-nearest neighbour). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919289ff-7e5b-4fed-bdc4-2d2ed8846cb1",
   "metadata": {},
   "source": [
    "# 1. ¿Cómo funciona este algoritmo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f3f2a-a75a-464f-a3fa-546fd4831369",
   "metadata": {},
   "source": [
    "Este algoritmo clasifica elementos a partir de un principio básico: las cosas que son parecidas tienen propiedades parecidas. Por ejemplo, los postres se parecen en que son dulces, pero también porque son echos por humanos a partir de varios productos que podemos identificar (eso los separa de las frutas).\n",
    "\n",
    "En ese sentido, el algoritmo clasifica elementos similares en una misma categoría _prestando información de otros para clasificarlo_. Es decir, a partir de sus _vecinos más cercanos_, el algoritmo clasifica los elementos no clasificados aún. Así, el algoritmo coge a los _k_ vecinos más cercanos y clasifica el nuevo elemento a partir de la clase mayoritaria que tengan sus vecinos.\n",
    "\n",
    "Veamos un ejemplo en vivo: hagamos que alguien pruebe un alimento misterioso.\n",
    "\n",
    "¿Qué hace esa persona?\n",
    "\n",
    "1. **Prueba el objeto:** tiene un nuevo elemento por clasificar y _mide_ sus características (dulzura, amargura, crocancia, textura).\n",
    "2. **Compara las características observadas con su base de datos (la memoria):** se ha entrenado por mucho tiempo probando cosas y recolectando sus características, por lo cual tiene puntos de comparación de los niveles de las características del nuevo elemento con las que conoce.\n",
    "3. **Define la clase del objeto - qué es - a partir de lo que conoce:** reconoce las características y clasifica a partir de su cercanía con otros objetos cuya clase ya conoce.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c8d63-1920-4c5d-9bc1-e5771f197815",
   "metadata": {},
   "source": [
    "## 1.1. Viendo como una computadora\n",
    "Veamos el ejemplo como lo vería una computadora:\n",
    "\n",
    "1. **Entrenamiento:** el computador _prueba_ varias cosas y mide sus características:\n",
    "\n",
    "<center><img src=\"Table_ingredients.png\" width = \"750\", height = \"500\"/></center>\n",
    "\n",
    "2. **Reconoce patrones:** los procesa de manera tal que pueda reconocer patrones:\n",
    "\n",
    "<center><img src=\"plot_ingredients.png\" width = \"500\", height = \"500\"/></center>\n",
    "\n",
    "3. **Compara los patrones con las clases:** encuentra que ellas tienen elementos comunes:\n",
    "\n",
    "<center><img src=\"plot_ingredients_groups.png\" width = \"500\", height = \"500\"/></center>\n",
    "\n",
    "4. **Clasifica con sus vecinos más cercanos:** compara con los k vecinos y clasifica:\n",
    "\n",
    "<center><img src=\"plot_ingredients_clas.png\" width = \"500\", height = \"500\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c99ab3e-85e1-44c4-af56-31a8d62051ed",
   "metadata": {},
   "source": [
    "## 1.2. La distancia entre elementos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c22315-5098-46fe-9acf-6d476d5672f8",
   "metadata": {},
   "source": [
    "El computador necesita poder saber qué tan cercanos están los elementos entre sí. Para ello, generalmente se utiliza una **distancia euclidiana** para saber cuán cerca están entre ellos los elementos. La distancia entre dos vectores, $p$ y $q$, se define así:\n",
    "\n",
    "$$ dist(p,q) = \\sqrt{\\sum^m_{i=1}(p_i - q_i)^2} $$\n",
    "\n",
    "En el ejemplo del tomate, tendríamos algo así:\n",
    "\n",
    "<center><img src=\"dist_table.png\" width = \"750\", height = \"300\"/></center>\n",
    "\n",
    "Ahora, debemos definir _k_, el cual es el **parámetro** que nos dice cuántos vecinos debe tomar el algoritmo para clasificar:\n",
    "\n",
    "* Si es $k=1$, el vecino más cercano es la naranja. Por tanto, el tomate es una fruta.\n",
    "* Si es $k=3$, los vecinos más cercanos son naranja, uva y nueces. Por tanto, el tomate sería una fruta.\n",
    "\n",
    "Este ejemplo nos da a entender que **la elección de _k_ es sumamente importante: determina cuál es la clasificación**. Sin embargo, hay un dilema entre **varianza y sesgo**.\n",
    "\n",
    "* Entre **mayor k, menor varianza** generada por datos ruidosos. Sin embargo, puede haber un **mayor sesgo**.\n",
    "    - Por ejemplo, si nuestra base de datos tuviera 15 observaciones de nueces, 15 de verduras y 10 de frutas, se clasificaría el tomate como una nuez si tomáramos todas las observaciones. Se clasifica como la clase mayoritaria.\n",
    "* Entre **menor k (muy pequeño)**, se podría **sesgar por datos ruidosos**.\n",
    "    - Por ejemplo, si hubiéramos clasificado mal una verdura o si hay un vecino más cercano pero que es atípico, estaríamos sesgando la clasificación.\n",
    "    \n",
    "Por ello, **no hay una regla general de cómo escoger el _k_, pero se toma una regla práctica que:**\n",
    "\n",
    "$$k = \\sqrt{k}$$\n",
    "\n",
    "No obstante, lo mejor es:\n",
    "\n",
    "* **Probar varios k** en la base de entrenamiento (base de validación).\n",
    "* Utilizar una **votación ponderada**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3372ac81-fd99-4670-a8a3-101765aa54e2",
   "metadata": {},
   "source": [
    "## 1.3. Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17bdcf3-1f3c-4e22-9073-9e651e2c834f",
   "metadata": {},
   "source": [
    "Dado que podemos tener que una variable puede tener un peso mayor solo por ser más grande, debemos procurar que:\n",
    "\n",
    "* Los datos estén en la misma métrica.\n",
    "* Reescalar los datos para que estén en rangos similares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c41eff-4feb-4645-bbd5-043fee0d5f10",
   "metadata": {},
   "source": [
    "### 1.3.1. Reescalamiento de datos: estandarización min-max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0d997-dc9a-4110-a977-76870d128188",
   "metadata": {},
   "source": [
    "Podemos estandarizar los datos con el proceso min-max:\n",
    "\n",
    "$$X_0 = \\frac{X-X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "Es decir, se resta el mínimo del valor y se divide por el rango. Por tanto, todos los datos se encuentran entre 0 y 1 y representa qué tan lejos se está del valor mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dff8aae-0125-4bab-b43e-c2565c5804c6",
   "metadata": {},
   "source": [
    "### 1.3.2. Reescalamiento de datos: normalización por Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6178187f-19d5-4b77-9846-62b6d8a4bc3a",
   "metadata": {},
   "source": [
    "Podemos estandarizar los datos con el Z-score:\n",
    "\n",
    "$$X_0 = \\frac{X-\\mu}{\\sigma}$$\n",
    "\n",
    "Es decir, se resta la media y se divide por la desviación estánar. Por tanto, todos los datos se encuentran en términos de desviación estándar de la media."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c80095-ac1f-4d04-bc87-e758df5a907c",
   "metadata": {},
   "source": [
    "### 1.3.3. Reescalamiento de dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00302e-44ca-4c25-9d19-659be35cbf12",
   "metadata": {},
   "source": [
    "No se puede utilizar distancia euclidiana para categorías nominales, por lo que generamos dummies. Esto es válido para una o más categorías y, además, ya están en estandarización min-max."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe25fbb-404b-42af-b22d-1654bc9ef156",
   "metadata": {},
   "source": [
    "# 2. Predicción de cáncer de seno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae63631-7bfe-4b39-85e4-3691a9ce3add",
   "metadata": {},
   "source": [
    "Utilicemos la base de datos de cáncer de seno para clasificar si una tomografía presentada tiene cáncer o no. Vamos a cargar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81610769-ed3d-4794-ada5-970ea0657ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the data\n",
    "data = pd.read_csv(\"wisc_bc_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09082130-9143-41ef-8e90-c2b093ca6814",
   "metadata": {},
   "source": [
    "> ¿Qué observamos? ¿Cómo son los datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5899ac21-239d-4b58-bf09-22021fc38bf9",
   "metadata": {},
   "source": [
    "## 2.1. Pre-procesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034968cd-7119-48cb-a510-4e37fbfb49bd",
   "metadata": {},
   "source": [
    "### 2.1.1. Procesamiento de tipos y datos\n",
    "\n",
    "Pregúntese los siguiente: ¿hay alguna variable que debe ser eliminada? ¿Por qué? Demos una pista: en este caso, debemos eliminar la variable `id`, dado que el modelo podría aprender de esa variable sobre las otras, identificando por el id y no por las variables que nos interesan. En ese sentido, podríamos experimentar un overfitting y, para evitarlo, reducimos dimensionalidad eliminando la columna.\n",
    "\n",
    "No obstante, esto es general. Es decir, **debemos eliminar cualquier variable que sirva de identificación única de las observaciones para evitar sesgos**. En el caso de las personas, ello incluye cédula, nombres y apellidos. En caso de unidades territoriales, los códigos que las identifican y, en algunos casos, elementos de niveles superiores, por ejemplo el código del municipio y el del departamento. Empero, **todo depende del caso**, ya que en ocasiones necesitaremos estos datos para predecir, como, por ejemplo, predecir el número de hectáreas de coca en un municipio para un año dado.\n",
    "\n",
    "> Teniendo en cuenta lo anterior, elimine la variable `id`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4b8f167-3823-4ccc-a6f0-6e32039cf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping id variable\n",
    "data = data.drop(\"id\", axis = 1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc886a3-6720-4a05-a738-0c60a5905592",
   "metadata": {},
   "source": [
    "Así mismo, debemos revisar las clases de las columnas: recuerden que en ocasiones no están como las necesitamos. El ejemplo más común ocurre cuando tenemos fechas y no las transformamos en tipo `datetime`, pero también ocurre cuando tenemos números y Python los lee como texto. ¡Debemos revisar bien cuáles son los tipos de nuestras variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62a36f07-0ae5-4c8a-888f-83661462c385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                   object\n",
       "radius_mean                float64\n",
       "texture_mean               float64\n",
       "perimeter_mean             float64\n",
       "area_mean                  float64\n",
       "smoothness_mean            float64\n",
       "compactness_mean           float64\n",
       "concavity_mean             float64\n",
       "concave points_mean        float64\n",
       "symmetry_mean              float64\n",
       "fractal_dimension_mean     float64\n",
       "radius_se                  float64\n",
       "texture_se                 float64\n",
       "perimeter_se               float64\n",
       "area_se                    float64\n",
       "smoothness_se              float64\n",
       "compactness_se             float64\n",
       "concavity_se               float64\n",
       "concave points_se          float64\n",
       "symmetry_se                float64\n",
       "fractal_dimension_se       float64\n",
       "radius_worst               float64\n",
       "texture_worst              float64\n",
       "perimeter_worst            float64\n",
       "area_worst                 float64\n",
       "smoothness_worst           float64\n",
       "compactness_worst          float64\n",
       "concavity_worst            float64\n",
       "concave points_worst       float64\n",
       "symmetry_worst             float64\n",
       "fractal_dimension_worst    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8adc3c0-3aa1-4a9f-b87a-7e36fb495e32",
   "metadata": {},
   "source": [
    "No hay problema con la mayoría de datos: todos ellos ya están codificados como variables `float`. No encontramos, por ejemplo, una que sea un número, pero Python lo esté leyendo como un texto.\n",
    "\n",
    "No obstante, **es conveniente que la variable de clasificación sea, precisamente, una categoría**. Las razones son las siguientes:\n",
    "\n",
    "* Al modelo de Machine Learning le es más sencillo saber cuáles son los elementos de predicción y que estos corresponden a unos valores genéricos (las categorías).\n",
    "* Al convertir en categoría podemos revisar si no hay errores ortográficos o de digitación (typos) en las categorías.\n",
    "\n",
    "En ese sentido:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c17e61-96ec-41c3-bbdc-efd86c27293b",
   "metadata": {},
   "source": [
    "#### Pequeño ejercicio\n",
    "\n",
    "> Obtenga la columna de diagnóstico y revíselo, conviértalo en tipo factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbfdc4-70d5-4590-a584-b9998cbd34d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bc417eb-3ba9-4084-b6be-d52731d2a4f6",
   "metadata": {},
   "source": [
    "### 2.3. Estandarización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b992c03-0d30-4e1b-9598-145f9f5a5e8d",
   "metadata": {},
   "source": [
    "Recordemos que este algoritmo es sensible a las medidas: un valor mayor tendrá más importancia que uno menor. Por esto, debemos estandarizarlo para mejorar su rendimiento. Para este caso, vamos a utilizar una estandarización min-max con el módulo `MinMaxScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0f0547c-6262-4036-998d-7d0884af0b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "121498c7-c37b-4c10-8f88-2bd5bff8bdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606901</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519744</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623266</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393099</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633582</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.521037  0.022658  0.545989  0.363733  0.593753  0.792037  0.703140   \n",
       "1    0.643144  0.272574  0.615783  0.501591  0.289880  0.181768  0.203608   \n",
       "2    0.601496  0.390260  0.595743  0.449417  0.514309  0.431017  0.462512   \n",
       "3    0.210090  0.360839  0.233501  0.102906  0.811321  0.811361  0.565604   \n",
       "4    0.629893  0.156578  0.630986  0.489290  0.430351  0.347893  0.463918   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "564  0.690000  0.428813  0.678668  0.566490  0.526948  0.296055  0.571462   \n",
       "565  0.622320  0.626987  0.604036  0.474019  0.407782  0.257714  0.337395   \n",
       "566  0.455251  0.621238  0.445788  0.303118  0.288165  0.254340  0.216753   \n",
       "567  0.644564  0.663510  0.665538  0.475716  0.588336  0.790197  0.823336   \n",
       "568  0.036869  0.501522  0.028540  0.015907  0.000000  0.074351  0.000000   \n",
       "\n",
       "           7         8         9   ...        20        21        22  \\\n",
       "0    0.731113  0.686364  0.605518  ...  0.620776  0.141525  0.668310   \n",
       "1    0.348757  0.379798  0.141323  ...  0.606901  0.303571  0.539818   \n",
       "2    0.635686  0.509596  0.211247  ...  0.556386  0.360075  0.508442   \n",
       "3    0.522863  0.776263  1.000000  ...  0.248310  0.385928  0.241347   \n",
       "4    0.518390  0.378283  0.186816  ...  0.519744  0.123934  0.506948   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "564  0.690358  0.336364  0.132056  ...  0.623266  0.383262  0.576174   \n",
       "565  0.486630  0.349495  0.113100  ...  0.560655  0.699094  0.520892   \n",
       "566  0.263519  0.267677  0.137321  ...  0.393099  0.589019  0.379949   \n",
       "567  0.755467  0.675253  0.425442  ...  0.633582  0.730277  0.668310   \n",
       "568  0.000000  0.266162  0.187026  ...  0.054287  0.489072  0.043578   \n",
       "\n",
       "           23        24        25        26        27        28        29  \n",
       "0    0.450698  0.601136  0.619292  0.568610  0.912027  0.598462  0.418864  \n",
       "1    0.435214  0.347553  0.154563  0.192971  0.639175  0.233590  0.222878  \n",
       "2    0.374508  0.483590  0.385375  0.359744  0.835052  0.403706  0.213433  \n",
       "3    0.094008  0.915472  0.814012  0.548642  0.884880  1.000000  0.773711  \n",
       "4    0.341575  0.437364  0.172415  0.319489  0.558419  0.157500  0.142595  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "564  0.452664  0.461137  0.178527  0.328035  0.761512  0.097575  0.105667  \n",
       "565  0.379915  0.300007  0.159997  0.256789  0.559450  0.198502  0.074315  \n",
       "566  0.230731  0.282177  0.273705  0.271805  0.487285  0.128721  0.151909  \n",
       "567  0.402035  0.619626  0.815758  0.749760  0.910653  0.497142  0.452315  \n",
       "568  0.020497  0.124084  0.036043  0.000000  0.000000  0.257441  0.100682  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Definimos el escalamiento\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Estandarizamos\n",
    "data_scaled = scaler.fit_transform(data.loc[:, data.columns != 'diagnosis'])\n",
    "data_scaled = pd.DataFrame(data_scaled)\n",
    "\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc533e44-e66d-41b3-8a78-a09aa50125c4",
   "metadata": {},
   "source": [
    "Normalmente no tenemos el tiempo (ni las ganas) de revisar minuciosamente todos los números. Por ello, podemos utilizar varias técnicas para para comprobar si nuestros procesos se realizaron como queríamos. Probemos uno en particular con el método `describe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a0e79ab-41a7-4ee3-a8b2-d8c340fd7b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.338222</td>\n",
       "      <td>0.323965</td>\n",
       "      <td>0.332935</td>\n",
       "      <td>0.216920</td>\n",
       "      <td>0.394785</td>\n",
       "      <td>0.260601</td>\n",
       "      <td>0.208058</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.379605</td>\n",
       "      <td>0.270379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296663</td>\n",
       "      <td>0.363998</td>\n",
       "      <td>0.283138</td>\n",
       "      <td>0.170906</td>\n",
       "      <td>0.404138</td>\n",
       "      <td>0.220212</td>\n",
       "      <td>0.217403</td>\n",
       "      <td>0.393836</td>\n",
       "      <td>0.263307</td>\n",
       "      <td>0.189596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.166787</td>\n",
       "      <td>0.145453</td>\n",
       "      <td>0.167915</td>\n",
       "      <td>0.149274</td>\n",
       "      <td>0.126967</td>\n",
       "      <td>0.161992</td>\n",
       "      <td>0.186785</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.138456</td>\n",
       "      <td>0.148702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171940</td>\n",
       "      <td>0.163813</td>\n",
       "      <td>0.167352</td>\n",
       "      <td>0.139932</td>\n",
       "      <td>0.150779</td>\n",
       "      <td>0.152649</td>\n",
       "      <td>0.166633</td>\n",
       "      <td>0.225884</td>\n",
       "      <td>0.121954</td>\n",
       "      <td>0.118466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.223342</td>\n",
       "      <td>0.218465</td>\n",
       "      <td>0.216847</td>\n",
       "      <td>0.117413</td>\n",
       "      <td>0.304595</td>\n",
       "      <td>0.139685</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>0.100944</td>\n",
       "      <td>0.282323</td>\n",
       "      <td>0.163016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180719</td>\n",
       "      <td>0.241471</td>\n",
       "      <td>0.167837</td>\n",
       "      <td>0.081130</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.116337</td>\n",
       "      <td>0.091454</td>\n",
       "      <td>0.223127</td>\n",
       "      <td>0.185098</td>\n",
       "      <td>0.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.302381</td>\n",
       "      <td>0.308759</td>\n",
       "      <td>0.293345</td>\n",
       "      <td>0.172895</td>\n",
       "      <td>0.390358</td>\n",
       "      <td>0.224679</td>\n",
       "      <td>0.144189</td>\n",
       "      <td>0.166501</td>\n",
       "      <td>0.369697</td>\n",
       "      <td>0.243892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250445</td>\n",
       "      <td>0.356876</td>\n",
       "      <td>0.235320</td>\n",
       "      <td>0.123206</td>\n",
       "      <td>0.397081</td>\n",
       "      <td>0.179110</td>\n",
       "      <td>0.181070</td>\n",
       "      <td>0.343402</td>\n",
       "      <td>0.247782</td>\n",
       "      <td>0.163977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.416442</td>\n",
       "      <td>0.408860</td>\n",
       "      <td>0.416765</td>\n",
       "      <td>0.271135</td>\n",
       "      <td>0.475490</td>\n",
       "      <td>0.340531</td>\n",
       "      <td>0.306232</td>\n",
       "      <td>0.367793</td>\n",
       "      <td>0.453030</td>\n",
       "      <td>0.340354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386339</td>\n",
       "      <td>0.471748</td>\n",
       "      <td>0.373475</td>\n",
       "      <td>0.220901</td>\n",
       "      <td>0.494156</td>\n",
       "      <td>0.302520</td>\n",
       "      <td>0.305831</td>\n",
       "      <td>0.554639</td>\n",
       "      <td>0.318155</td>\n",
       "      <td>0.242949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  569.000000   \n",
       "mean     0.338222    0.323965    0.332935    0.216920    0.394785    0.260601   \n",
       "std      0.166787    0.145453    0.167915    0.149274    0.126967    0.161992   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.223342    0.218465    0.216847    0.117413    0.304595    0.139685   \n",
       "50%      0.302381    0.308759    0.293345    0.172895    0.390358    0.224679   \n",
       "75%      0.416442    0.408860    0.416765    0.271135    0.475490    0.340531   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9   ...          20  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  ...  569.000000   \n",
       "mean     0.208058    0.243137    0.379605    0.270379  ...    0.296663   \n",
       "std      0.186785    0.192857    0.138456    0.148702  ...    0.171940   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      0.069260    0.100944    0.282323    0.163016  ...    0.180719   \n",
       "50%      0.144189    0.166501    0.369697    0.243892  ...    0.250445   \n",
       "75%      0.306232    0.367793    0.453030    0.340354  ...    0.386339   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "               21          22          23          24          25          26  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  569.000000   \n",
       "mean     0.363998    0.283138    0.170906    0.404138    0.220212    0.217403   \n",
       "std      0.163813    0.167352    0.139932    0.150779    0.152649    0.166633   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.241471    0.167837    0.081130    0.300007    0.116337    0.091454   \n",
       "50%      0.356876    0.235320    0.123206    0.397081    0.179110    0.181070   \n",
       "75%      0.471748    0.373475    0.220901    0.494156    0.302520    0.305831   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               27          28          29  \n",
       "count  569.000000  569.000000  569.000000  \n",
       "mean     0.393836    0.263307    0.189596  \n",
       "std      0.225884    0.121954    0.118466  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.223127    0.185098    0.107700  \n",
       "50%      0.343402    0.247782    0.163977  \n",
       "75%      0.554639    0.318155    0.242949  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe: debe decirnos si hay un máximo y un mínimo de acuerdo con lo que queremos\n",
    "data_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ba522-0303-4ba7-a145-728eddfbf984",
   "metadata": {},
   "source": [
    "> ¿Qué deberíamos revisar para saber si el escalamiento se realizó correctamente?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d3c3cd-a0ea-4c9a-97a7-208e0e0994f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "387c4769-ccf3-47f5-a6a6-fa06c827cc2a",
   "metadata": {},
   "source": [
    "### 2.4. Base de datos de testeo y entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c4df2-8753-4fdd-91ec-7b8cd99796d2",
   "metadata": {},
   "source": [
    "¡Recordes el mantra!\n",
    "\n",
    "<center> <b> Se debe separar la base de datos entre base de entrenamiento y testeo. </b> </center> <br>\n",
    "\n",
    "\n",
    "Realicemos dicho proceso son el paquete `sklearn`, con el módulo `model_selection`. Sin embargo, primero debemos separar la variable dependiente en un solo objeto para que el paquete también las separe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0719b2f-3297-46df-b7a5-d0cf56cd3a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      M\n",
       "4      M\n",
       "      ..\n",
       "564    M\n",
       "565    M\n",
       "566    M\n",
       "567    M\n",
       "568    B\n",
       "Name: diagnosis, Length: 569, dtype: category\n",
       "Categories (2, object): ['M', 'B']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna de diagnóstico y lo separamos de las variables independientes\n",
    "y = data[\"diagnosis\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2269e2cc-2142-49c1-8632-d0323550aeb9",
   "metadata": {},
   "source": [
    "> **¡Cuidado!** En este punto ya habíamos separado las variables independientes de la dependiente: cuando escalamos las variables, removimos la dependiente porque no se podía transformar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3168af6-7c56-4456-907f-b39a58a1715d",
   "metadata": {},
   "source": [
    "Ahora sí, tenemos para las **variables independientes** al objeto `data_scaled` y para la **variable independiente** tenemos el objeto, vector, `y`. Ahora sí podemos separar de manera aleatoria las bases de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f53bc07-b467-427c-8d00-013c8d77b352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. de ejemplos de entrenamiento: 455\n",
      "No. de ejemplos de testeo: 114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.305220</td>\n",
       "      <td>0.335475</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.178961</td>\n",
       "      <td>0.341699</td>\n",
       "      <td>0.133427</td>\n",
       "      <td>0.137254</td>\n",
       "      <td>0.170875</td>\n",
       "      <td>0.271717</td>\n",
       "      <td>0.142165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357524</td>\n",
       "      <td>0.475746</td>\n",
       "      <td>0.329648</td>\n",
       "      <td>0.198683</td>\n",
       "      <td>0.455194</td>\n",
       "      <td>0.123517</td>\n",
       "      <td>0.211182</td>\n",
       "      <td>0.398625</td>\n",
       "      <td>0.260004</td>\n",
       "      <td>0.122458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.249373</td>\n",
       "      <td>0.278323</td>\n",
       "      <td>0.238270</td>\n",
       "      <td>0.134380</td>\n",
       "      <td>0.306130</td>\n",
       "      <td>0.145421</td>\n",
       "      <td>0.091026</td>\n",
       "      <td>0.115855</td>\n",
       "      <td>0.459596</td>\n",
       "      <td>0.259478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201352</td>\n",
       "      <td>0.351812</td>\n",
       "      <td>0.180238</td>\n",
       "      <td>0.093148</td>\n",
       "      <td>0.333686</td>\n",
       "      <td>0.146996</td>\n",
       "      <td>0.155192</td>\n",
       "      <td>0.282165</td>\n",
       "      <td>0.305145</td>\n",
       "      <td>0.172373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.239434</td>\n",
       "      <td>0.623267</td>\n",
       "      <td>0.228457</td>\n",
       "      <td>0.129968</td>\n",
       "      <td>0.314977</td>\n",
       "      <td>0.124594</td>\n",
       "      <td>0.055459</td>\n",
       "      <td>0.118141</td>\n",
       "      <td>0.401010</td>\n",
       "      <td>0.147852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201708</td>\n",
       "      <td>0.567964</td>\n",
       "      <td>0.183425</td>\n",
       "      <td>0.093983</td>\n",
       "      <td>0.217460</td>\n",
       "      <td>0.067885</td>\n",
       "      <td>0.044121</td>\n",
       "      <td>0.190619</td>\n",
       "      <td>0.165385</td>\n",
       "      <td>0.074446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.723603</td>\n",
       "      <td>0.336828</td>\n",
       "      <td>0.753300</td>\n",
       "      <td>0.579215</td>\n",
       "      <td>0.721946</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.906064</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.430286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728211</td>\n",
       "      <td>0.426173</td>\n",
       "      <td>0.778873</td>\n",
       "      <td>0.534506</td>\n",
       "      <td>0.653305</td>\n",
       "      <td>0.652376</td>\n",
       "      <td>0.767412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490834</td>\n",
       "      <td>0.281057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.225235</td>\n",
       "      <td>0.145756</td>\n",
       "      <td>0.210421</td>\n",
       "      <td>0.120382</td>\n",
       "      <td>0.230207</td>\n",
       "      <td>0.073676</td>\n",
       "      <td>0.052601</td>\n",
       "      <td>0.137326</td>\n",
       "      <td>0.525758</td>\n",
       "      <td>0.235257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191391</td>\n",
       "      <td>0.166311</td>\n",
       "      <td>0.170775</td>\n",
       "      <td>0.085652</td>\n",
       "      <td>0.214158</td>\n",
       "      <td>0.055991</td>\n",
       "      <td>0.053794</td>\n",
       "      <td>0.284880</td>\n",
       "      <td>0.302779</td>\n",
       "      <td>0.077660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "171  0.305220  0.335475  0.290581  0.178961  0.341699  0.133427  0.137254   \n",
       "155  0.249373  0.278323  0.238270  0.134380  0.306130  0.145421  0.091026   \n",
       "471  0.239434  0.623267  0.228457  0.129968  0.314977  0.124594  0.055459   \n",
       "108  0.723603  0.336828  0.753300  0.579215  0.721946  0.789583  0.999063   \n",
       "281  0.225235  0.145756  0.210421  0.120382  0.230207  0.073676  0.052601   \n",
       "\n",
       "           7         8         9   ...        20        21        22  \\\n",
       "171  0.170875  0.271717  0.142165  ...  0.357524  0.475746  0.329648   \n",
       "155  0.115855  0.459596  0.259478  ...  0.201352  0.351812  0.180238   \n",
       "471  0.118141  0.401010  0.147852  ...  0.201708  0.567964  0.183425   \n",
       "108  0.906064  0.755556  0.430286  ...  0.728211  0.426173  0.778873   \n",
       "281  0.137326  0.525758  0.235257  ...  0.191391  0.166311  0.170775   \n",
       "\n",
       "           23        24        25        26        27        28        29  \n",
       "171  0.198683  0.455194  0.123517  0.211182  0.398625  0.260004  0.122458  \n",
       "155  0.093148  0.333686  0.146996  0.155192  0.282165  0.305145  0.172373  \n",
       "471  0.093983  0.217460  0.067885  0.044121  0.190619  0.165385  0.074446  \n",
       "108  0.534506  0.653305  0.652376  0.767412  1.000000  0.490834  0.281057  \n",
       "281  0.085652  0.214158  0.055991  0.053794  0.284880  0.302779  0.077660  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos el módulo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separamos las bases de datos con un 20% de testeo y 80% de entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, y, test_size = 0.2)\n",
    "\n",
    "print(f\"No. de ejemplos de entrenamiento: {y_train.shape[0]}\")\n",
    "print(f\"No. de ejemplos de testeo: {y_test.shape[0]}\")\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1e05f-7f12-40c9-a131-9f6ed06ee722",
   "metadata": {},
   "source": [
    "Hay que tener cuidado en la replicabilidad de los datos. Es decir, dado que la función `train_test_split` realiza una división aleatoria de los datos, debería ocurrir que, cada vez que hagamos el proceso, realice una división diferente. Para comprobarlo, corra el código de arriba múltiples veces y revise cómo cambian los valores.\n",
    "\n",
    "Para evitar esto, la función `train_test_split` tiene un argumento que permite **plantar una semilla**. Es decir, permite tener un estado aleatorio preciso que permita la replicabilidad en otros momentos y otras máquinas. Este argumento se llama `random_state` y se le agrega un número de su preferencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c640b334-b8fb-451d-ba6b-06a7e9c71ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. de ejemplos de entrenamiento: 455\n",
      "No. de ejemplos de testeo: 114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.145251</td>\n",
       "      <td>0.264457</td>\n",
       "      <td>0.142492</td>\n",
       "      <td>0.070965</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.165266</td>\n",
       "      <td>0.058833</td>\n",
       "      <td>0.088221</td>\n",
       "      <td>0.419192</td>\n",
       "      <td>0.281171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114906</td>\n",
       "      <td>0.394989</td>\n",
       "      <td>0.107426</td>\n",
       "      <td>0.048860</td>\n",
       "      <td>0.455854</td>\n",
       "      <td>0.109546</td>\n",
       "      <td>0.084265</td>\n",
       "      <td>0.223333</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.141677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.180747</td>\n",
       "      <td>0.414948</td>\n",
       "      <td>0.172759</td>\n",
       "      <td>0.091792</td>\n",
       "      <td>0.319401</td>\n",
       "      <td>0.116711</td>\n",
       "      <td>0.084677</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.482828</td>\n",
       "      <td>0.206613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171825</td>\n",
       "      <td>0.533582</td>\n",
       "      <td>0.165745</td>\n",
       "      <td>0.074789</td>\n",
       "      <td>0.390477</td>\n",
       "      <td>0.138070</td>\n",
       "      <td>0.153914</td>\n",
       "      <td>0.257216</td>\n",
       "      <td>0.275971</td>\n",
       "      <td>0.141545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.433480</td>\n",
       "      <td>0.174163</td>\n",
       "      <td>0.418147</td>\n",
       "      <td>0.278473</td>\n",
       "      <td>0.382053</td>\n",
       "      <td>0.201307</td>\n",
       "      <td>0.128866</td>\n",
       "      <td>0.225050</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.185131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347919</td>\n",
       "      <td>0.201493</td>\n",
       "      <td>0.326162</td>\n",
       "      <td>0.187451</td>\n",
       "      <td>0.326421</td>\n",
       "      <td>0.140592</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.387973</td>\n",
       "      <td>0.239109</td>\n",
       "      <td>0.098911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.246060</td>\n",
       "      <td>0.274941</td>\n",
       "      <td>0.234953</td>\n",
       "      <td>0.130477</td>\n",
       "      <td>0.468268</td>\n",
       "      <td>0.157015</td>\n",
       "      <td>0.058341</td>\n",
       "      <td>0.146173</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.345198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174315</td>\n",
       "      <td>0.237207</td>\n",
       "      <td>0.158026</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.282837</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.039776</td>\n",
       "      <td>0.202131</td>\n",
       "      <td>0.130495</td>\n",
       "      <td>0.122786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.249373</td>\n",
       "      <td>0.430504</td>\n",
       "      <td>0.237648</td>\n",
       "      <td>0.137010</td>\n",
       "      <td>0.264422</td>\n",
       "      <td>0.100055</td>\n",
       "      <td>0.040159</td>\n",
       "      <td>0.062674</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.206403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221985</td>\n",
       "      <td>0.532249</td>\n",
       "      <td>0.210817</td>\n",
       "      <td>0.107575</td>\n",
       "      <td>0.359440</td>\n",
       "      <td>0.148548</td>\n",
       "      <td>0.098243</td>\n",
       "      <td>0.217698</td>\n",
       "      <td>0.302582</td>\n",
       "      <td>0.177030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "338  0.145251  0.264457  0.142492  0.070965  0.433962  0.165266  0.058833   \n",
       "427  0.180747  0.414948  0.172759  0.091792  0.319401  0.116711  0.084677   \n",
       "406  0.433480  0.174163  0.418147  0.278473  0.382053  0.201307  0.128866   \n",
       "96   0.246060  0.274941  0.234953  0.130477  0.468268  0.157015  0.058341   \n",
       "490  0.249373  0.430504  0.237648  0.137010  0.264422  0.100055  0.040159   \n",
       "\n",
       "           7         8         9   ...        20        21        22  \\\n",
       "338  0.088221  0.419192  0.281171  ...  0.114906  0.394989  0.107426   \n",
       "427  0.069781  0.482828  0.206613  ...  0.171825  0.533582  0.165745   \n",
       "406  0.225050  0.340909  0.185131  ...  0.347919  0.201493  0.326162   \n",
       "96   0.146173  0.424242  0.345198  ...  0.174315  0.237207  0.158026   \n",
       "490  0.062674  0.244444  0.206403  ...  0.221985  0.532249  0.210817   \n",
       "\n",
       "           23        24        25        26        27        28        29  \n",
       "338  0.048860  0.455854  0.109546  0.084265  0.223333  0.261975  0.141677  \n",
       "427  0.074789  0.390477  0.138070  0.153914  0.257216  0.275971  0.141545  \n",
       "406  0.187451  0.326421  0.140592  0.184505  0.387973  0.239109  0.098911  \n",
       "96   0.076190  0.282837  0.064315  0.039776  0.202131  0.130495  0.122786  \n",
       "490  0.107575  0.359440  0.148548  0.098243  0.217698  0.302582  0.177030  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos el módulo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separamos las bases de datos con un 20% de testeo y 80% de entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(f\"No. de ejemplos de entrenamiento: {y_train.shape[0]}\")\n",
    "print(f\"No. de ejemplos de testeo: {y_test.shape[0]}\")\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd6f7b-5146-459b-bcaf-e4ae0fe625a4",
   "metadata": {},
   "source": [
    "> **Nota:** la separación debe ser aleatoria para no sesgar el entrenamiento. Ahora, hay ocasiones en los que no debe ser completamente aleatoria la elección, sino cuasialeatoria (si hay desbalance en la base de datos) o escogiendo las últimas observaciones si tenemos una base de datos de series de tiempo o panel (es decir, bases de datos que varían con el tiempo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a90a7-b411-42e3-9562-2a65c24a1f76",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "\n",
    "### Nota sobre la notación:\n",
    "\n",
    "La notación matemática tiene un significado incluso en el código. Se debe recordar que una matriz se escribe con una letra mayúscula y un vector se escribe con una letra minúscula. Por ello, cuando nos referimos a la matriz de covariables (variables independientes) escribimos una $X$ mayúscula y cuando nos referimos al vector de la variable de clasificación (variable dependiente) escribimos una $y$ minúscula.\n",
    "\n",
    "En ese sentido, las matrices de covariables de entrenamiento y testeo se suelen llamar `X_train` y `X_test` (se puede escoger cualquier nombre). Así mismo, los vectores de la variable de clasificación se suelen llamar `y_train` y `y_test`.\n",
    "\n",
    "De la misma manera, cabe resaltar que en los textos y libros de referencia también realizan esa diferencia, tal que las matrices se representan con `X`, `A` o como se desee llamar (letra mayúscula) y los vectores se representan con `y`, `b` o como se deseen llamar.\n",
    "\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a84a6-e849-4be0-a94d-eab810ff1a66",
   "metadata": {},
   "source": [
    "### 2.5. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b22a5-43be-4c0a-943d-9da60a32a086",
   "metadata": {},
   "source": [
    "Ahora que tenemos las bases de datos separadas, podemos entrenar nuestro modelo. Para ello utilizaremos el paquete `sklearn`, el cual ofrece múltiples algoritmos de Machine Learning en el siguiente [enlace](https://scikit-learn.org/stable/). La documentación que utiliza es muy completa y hace fácil aprender cómo construir y aplicar algoritmos de ML en Python.\n",
    "\n",
    "Por ahora, utilizaremos el módulo `neighbors` para algoritmos de vecinos más cercanos. En este caso, utilizaremos `KNeighborsClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fdfd02c1-c4a6-4c1c-9269-d80fb7aee4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'M', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se importa la librería y módulo\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Se especifica el algoritmo\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# Se entrena el modelo con las bases de datos de entrenamiento\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Se predice el resultado\n",
    "y_pred = knn.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3bb994f1-0a7e-4fb4-9e91-0cff5cfb9c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb95e79-5349-4220-8017-5e9d2a3d2a85",
   "metadata": {},
   "source": [
    "Miremos que la predicción corresponde con las categorías que utilizamos anteriormente. Además, utiliza las variables independientes de **testeo** para realizar la predicción, así que `y_pred` no son los valores reales, sino los valores que el modelo predice que debe ser el valor real a partir de las variables independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7c9d0-ac59-42d2-be06-265430752297",
   "metadata": {},
   "source": [
    "### 2.6. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1beeb3-a898-4b58-9820-9fe409fb2c82",
   "metadata": {},
   "source": [
    "### 2.6.1. Precisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be173fdf-0e13-4115-a91a-f3e75921eeae",
   "metadata": {},
   "source": [
    "Resulta muy importante observar cómo se desempeña el modelo, por lo cual debemos evaluarlo. Para los casos de clasificación resulta más sencillo entender la lógica detrás, ya que solamente debemos clasificar entre aquellas predicciones que realizó bien y las que realizó mal. Para ello, utilizamos la precisión (_acuracy_ en inglés) para evaluar qué tan bueno fue el modelo para predecir ambas clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "148a47be-f576-421e-b346-d0b84f9c4a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "# Se importa el módulo de métricas\n",
    "from sklearn import metrics\n",
    "\n",
    "# Se calcula la precisión del modelo\n",
    "print(\"Accuracy:\", round(metrics.accuracy_score(y_test, y_pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af44bbc-38b4-4602-8720-895dcbb30e2b",
   "metadata": {},
   "source": [
    "Esto simplemente se calcula de la siguiente manera:\n",
    "\n",
    "$$ Accuracy = \\frac{Valores correctamente predichos}{Total}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b1364-33b5-4909-92f2-eb9242fb18ad",
   "metadata": {},
   "source": [
    "### 2.6.2. Matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567d216-d40f-402e-8426-121d2c060f97",
   "metadata": {},
   "source": [
    "¡Es un buen número! Alto para un modelo de ML. Sin embargo, debemos tener en cuenta que **todo depende del problema específico que estamos viendo**. Veamos un poco más a profundidad esto con las **matrices de confusión**.\n",
    "\n",
    "Las matrices de confusión son herramientas de visualización que ayudan a entender el desempeño del modelo: en las columnas tenemos las predicciones y en las filas tenemos los valores reales. Su organización permite ver los verdaderos positivos, los verdaderos negativos, los falsos positivos y los falsos negativos.\n",
    "\n",
    "<center><img src=\"confusion_matrix.png\" width = \"450\", height = \"300\"/></center>\n",
    "\n",
    "Construyamos una a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "18109b67-1078-477a-9ca5-ec4b365da3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67,  0],\n",
       "       [ 4, 43]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se importa el módulo\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Se construye la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b170c67a-5649-4584-82b8-c45a85b1521e",
   "metadata": {},
   "source": [
    "No se ve muy bien esta matriz y tampoco se entiende muy bien. Utilicemos el siguiente código para construirla visualmente más entendible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "86ad9f31-72f3-4fdb-bb33-722fe6e1f21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se importan las librerías\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Se construye un mapa de calor\n",
    "ax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues')\n",
    "\n",
    "# Se agrega título y nombre a los ejes\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "# Se agregan subtítulos de categoría a la tabla\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "# Se muestra la imagen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4ad43-649f-41b6-8138-9d6cf6d7b666",
   "metadata": {},
   "source": [
    "### 2.6.3. Sensitividad & especificidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ef26e9-ae97-49e3-8683-94f918d733c8",
   "metadata": {},
   "source": [
    "Ahora, no siempre conviene mirar el desempeño del modelo en ambos campos (positivos y negativos), sino en uno de ellos en específico. Para ello se calcula la **sensitividad (_sensitivity_)** y la **especificidad (_specificity_)**. Ellas se definen como:\n",
    "\n",
    "* La **Sensitividad** mide la proporción de verdaderos positivos que fueron correctamente clasificados.\n",
    "\n",
    "$$ Sensitivity = \\frac{TP}{TP+FN} $$\n",
    "\n",
    "* La **Especificdad** mide la proporción de verdaderos negativos que fueron correctamente clasificados.\n",
    "\n",
    "$$ Specificity = \\frac{TN}{TN+FP} $$\n",
    "\n",
    "A la vez, tenemos en nuestra nueva notación que la precisión es\n",
    "\n",
    "$$ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN} $$\n",
    "\n",
    "Calculemos la sensitividad y especificidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d12f8dea-b58a-4f9b-bbc8-7e58e9822c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitividad del modelo: \t0.9736842105263158\n",
      "Especificidad del modelo: \t0.9868421052631579\n"
     ]
    }
   ],
   "source": [
    "# Se construye la matriz\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Se guardan los valores\n",
    "TP = confusion[1,1] # true positive\n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "print(\"Sensitividad del modelo: \\t{0}\".format(TP / float(TP+FN)))\n",
    "print(\"Especificidad del modelo: \\t{0}\".format(TN / float(TN+FP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbace3d-bb72-4c1e-b12b-c17e6b5ae24c",
   "metadata": {},
   "source": [
    "### 2.6.4. Precision & Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb51aee-e22b-40cf-baae-ffdf252a1193",
   "metadata": {},
   "source": [
    "La precision y el recall son otras dos medidas que intentan ver otro tipo de desempeño del modelo. Para este caso, tenemos que:\n",
    "\n",
    "* La **Precision** mide la proporción de positivos que son efectivamente positivos. Es decir, ya no mira la proporción de positivos correctamente clasificados, sino que, de los que se clasificaron como positivos, cuántos son realmente positivos.\n",
    "\n",
    "$$ precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "* La **Recall** mide qué tan completos están los resultados. En este caso, se pregunta cuál es la proporción de positivos clasificados como tal entre los que verdaderamente son positivos. Es decir, recall y sensitivity son lo mismo, solo que la interpretación difiere.\n",
    "\n",
    "$$ recall = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f7bbdc68-4f19-4859-9b09-a589edeb8bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo: \t1.0\n",
      "Recall del modelo: \t0.9148936170212766\n"
     ]
    }
   ],
   "source": [
    "# Se construye la matriz\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Se guardan los valores\n",
    "TP = confusion[1,1] # true positive\n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "print(\"Precision del modelo: \\t{0}\".format(TP / float(TP+FP)))\n",
    "print(\"Recall del modelo: \\t{0}\".format(TP / float(TP+FN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023ecf74-b295-43e5-8cb2-a73e9689bc28",
   "metadata": {},
   "source": [
    "### 2.6.5. F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd4e6e5-e89a-4a0c-a81c-6ba6cf344797",
   "metadata": {},
   "source": [
    "El F1 Score es una medida que combina, a la vez, la precision y el recall del modelo. El F1 Score es la media armónica de ambos, por lo cual su fórmula es la siguiente:\n",
    "\n",
    "$$ F1 = \\frac{2*precision*recall}{recall+precision} = \\frac{2*TP}{2*TP + FP + FN} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "da419243-5750-4fb6-8c70-7f97c98e5dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'M', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e40bab8a-be0a-497f-bc6d-5127ede1c7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710144927536231"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_pred, pos_label = \"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d15653-f3b1-4f3b-808d-2fac1837fccb",
   "metadata": {},
   "source": [
    "# 3. Perfeccionamiento del modelo de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f9c9cd-350d-47b2-9d3a-f6c96f985c6c",
   "metadata": {},
   "source": [
    "Siempre podemos mejorar. En este caso, vamos a hacer varios procesos para mejorar nuestro desempeño del modelo. En ese sentido, hay varias técnicas. No obstante, primero debemos crear una base de datos de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "451d66f7-42f1-4694-bfac-3577ca69f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. de ejemplos de entrenamiento: 364\n",
      "No. de ejemplos de validación: 91\n",
      "No. de ejemplos de testeo: 114\n"
     ]
    }
   ],
   "source": [
    "# Importamos el módulo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separamos las bases de datos con un 20% de testeo y 80% de entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Separamos las bases de datos con un 20% de validación y 80% de entrenamiento\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(f\"No. de ejemplos de entrenamiento: {y_train.shape[0]}\")\n",
    "print(f\"No. de ejemplos de validación: {y_val.shape[0]}\")\n",
    "print(f\"No. de ejemplos de testeo: {y_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62318842-b6e4-4db7-8bcf-dc27fb506ab2",
   "metadata": {},
   "source": [
    "> ¡Cuidado! Este ejemplo está peligrosamente en el límite de datos para la división con la base de datos de validación. No hay muchos datos, entonces siempre se debe preguntar si es conveniente o no separar las bases de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a484f-7c6b-4a95-9a58-8e7299789e96",
   "metadata": {},
   "source": [
    "## 3.1. Tuneo de parámetros manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b4c275-c734-41bb-9ffc-fd4ad3edf7f7",
   "metadata": {},
   "source": [
    "Una manera para mejorar el rendimiento de nuestro modelo es realizar ciclos para elegir los hiperparámetros que nos otorgarán un mejor rendimiento. Intentemos algo sencillo: revisemos diferentes valores de k vecinos.\n",
    "\n",
    "Ahora, para evaluar cuál es el mejor modelo, debemos **definir cuál es la métrica adecuada** para perfeccionarlo. Para este caso, dado que nos resultan importantes tanto predecir bien los verdaderos positivos como negativos, vamos a utilizar el F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "985d0b8d-0f34-4811-bab4-73201a85181f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOE\n",
      "EOF\n",
      "Elapsed time:  1.476541519165039\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Se importa la librería y módulo\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Se empieza a contar el tiempo\n",
    "start = time.time()\n",
    "print(\"BOE\")\n",
    "\n",
    "# Se crea una base de datos para guardar los resultados\n",
    "res = pd.DataFrame(columns = [\"k\", \"f1_score\"])\n",
    "\n",
    "# Se especifica el algoritmo\n",
    "for k in range(1, 101):\n",
    "    #print(k)\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "\n",
    "    # Se entrena el modelo con las bases de datos de entrenamiento\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Se predice el resultado\n",
    "    y_pred = knn.predict(X_val)\n",
    "    \n",
    "    # Se agregan los resultados\n",
    "    res = res.append({\"k\": k, \"f1_score\" : f1_score(y_val, y_pred, pos_label = \"B\")}, ignore_index = True)\n",
    "    \n",
    "    \n",
    "print(\"EOF\")\n",
    "end = time.time()\n",
    "print(\"Elapsed time: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d19f4-7d23-41f0-bcfb-97ac53d920e7",
   "metadata": {},
   "source": [
    "Veamos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3a17e476-86fa-4db3-a82c-69d81e3477df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "sns.lineplot(x = \"k\", y = \"f1_score\", data = res)\n",
    "plt.title(\"F1 Score by number of neighbours\")\n",
    "plt.xlabel(\"Number of neighbours\");plt.ylabel(\"F1 Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad185e4-05cb-4888-8ecb-539be09f8976",
   "metadata": {},
   "source": [
    "Ahora, encontremos aquellos valores donde se maximiza el F1 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ae582920-5943-4ca9-a6fc-944ea57b6891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k  f1_score\n",
       "2    3.0  0.982143\n",
       "3    4.0  0.982143\n",
       "4    5.0  0.982143\n",
       "5    6.0  0.982143\n",
       "6    7.0  0.982143\n",
       "7    8.0  0.982143\n",
       "8    9.0  0.982143\n",
       "9   10.0  0.982143\n",
       "10  11.0  0.982143\n",
       "11  12.0  0.982143\n",
       "12  13.0  0.982143"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res.f1_score == res.f1_score.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d5fa1-865b-4659-883c-56ae86206226",
   "metadata": {},
   "source": [
    "Al parecer, tenemos varios candidatos. En ocasiones, menos es mejor, entonces podríamos utilizar un cómodo `k=3`. Pero revisemos con precisión balanceada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "70517c76-87de-4e7a-922d-eb1255ad2e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOE\n",
      "EOF\n",
      "Elapsed time:  1.425110101699829\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Se importa la librería y módulo\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Se empieza a contar el tiempo\n",
    "start = time.time()\n",
    "print(\"BOE\")\n",
    "\n",
    "# Se crea una base de datos para guardar los resultados\n",
    "res = pd.DataFrame(columns = [\"k\", \"balanced_accuracy\"])\n",
    "\n",
    "# Se especifica el algoritmo\n",
    "for k in range(1, 101):\n",
    "    #print(k)\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "\n",
    "    # Se entrena el modelo con las bases de datos de entrenamiento\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Se predice el resultado\n",
    "    y_pred = knn.predict(X_val)\n",
    "    \n",
    "    # Se agregan los resultados\n",
    "    res = res.append({\"k\": k, \"balanced_accuracy\" : balanced_accuracy_score(y_val, y_pred)}, ignore_index = True)\n",
    "    \n",
    "    \n",
    "print(\"EOF\")\n",
    "end = time.time()\n",
    "print(\"Elapsed time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6e8ec5ff-adc5-4494-8f6d-f1ba731a971b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k  balanced_accuracy\n",
       "2    3.0           0.972222\n",
       "3    4.0           0.972222\n",
       "4    5.0           0.972222\n",
       "5    6.0           0.972222\n",
       "6    7.0           0.972222\n",
       "7    8.0           0.972222\n",
       "8    9.0           0.972222\n",
       "9   10.0           0.972222\n",
       "10  11.0           0.972222\n",
       "11  12.0           0.972222\n",
       "12  13.0           0.972222"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res.balanced_accuracy == res.balanced_accuracy.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecccaeb-43a9-40e1-a9d5-72d98a6f1963",
   "metadata": {},
   "source": [
    "¡Resulta lo mismo! Al parecer, tenemos un buen modelo al haber escogido `k = 3`. Ahora analicemos cómo nos fue con nuestro modelo final la base de datos de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3d6f1406-e824-4e8b-a9e3-52961d1f5e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710144927536231"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se importa la librería y módulo\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Se especifica el algoritmo\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# Se entrena el modelo con las bases de datos de entrenamiento\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Se predice el resultado\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Se evalúa \n",
    "f1_score(y_test, y_pred, pos_label = \"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df5c655-4c2f-4a72-92bc-1de44f740b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
